# FantasyPros Analytics

A **simple, clean data pipeline** for scraping FantasyPros rankings and serving them via API for analytics. Built for hobby-grade fantasy football analysis.

## ğŸ¯ **What This Does**

- **Scrapes** FantasyPros consensus rankings (all positions, scoring types, weeks)
- **Stores** data in PostgreSQL with proper indexing
- **Serves** data via clean REST API  
- **Automates** data collection with simple scheduling
- **Containerized** for easy deployment

## ğŸ—ï¸ **Simple Architecture**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   FantasyPros   â”‚â”€â”€â”€â–¶â”‚   Scraper    â”‚â”€â”€â”€â–¶â”‚ PostgreSQL â”‚
â”‚     Website     â”‚    â”‚              â”‚    â”‚  Database  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                   â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”‚
â”‚   Frontend      â”‚â—€â”€â”€â”€â”‚  FastAPI     â”‚â—€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚   Analytics     â”‚    â”‚   Server     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸš€ **Quick Start**

### **Option 1: Docker (Recommended)**

```bash
# Clone and start everything
git clone <repo>
cd fantasypros-scraper

# Start database + API + scheduler
docker-compose up -d

# Initialize database tables
docker-compose exec app python main.py init

# Run initial scraping
docker-compose exec app python main.py scrape --week 0

# View API at http://localhost:8000
```

### **Option 2: Local Development**

```bash
# Setup
python -m venv venv
source venv/bin/activate  # or `venv\Scripts\activate` on Windows
pip install -r requirements.txt

# Database (install PostgreSQL locally)
export DATABASE_URL="postgresql://user:pass@localhost:5432/fantasypros"

# Initialize
python main.py init

# Scrape data
python main.py scrape --week 0

# Start API server
python main.py server
```

## ğŸ“š **Usage**

### **CLI Commands**

```bash
# Initialize database
python main.py init

# Manual scraping
python main.py scrape --week 0                    # All draft rankings
python main.py scrape --position QB --week 1      # QB week 1
python main.py scrape --position RB --scoring PPR # RB draft PPR

# Start services
python main.py server                             # API server
python main.py scheduler                          # Automated scraping

# Check status
python main.py status
```

### **API Endpoints**

```bash
# Get rankings
GET /rankings/QB?week=0&scoring=STD              # QB draft standard
GET /rankings/RB?week=1&scoring=PPR&limit=50     # RB week 1 PPR

# Player data
GET /players/Josh%20Allen                        # Player history

# Metadata
GET /positions                                   # Available positions
GET /weeks?year=2025                            # Available weeks
GET /stats                                       # System stats

# Manual scraping (admin)
POST /admin/scrape/draft                         # Trigger draft scrape
POST /admin/scrape/weekly?week=1                 # Trigger weekly scrape
```

## ğŸ—„ï¸ **Data Schema**

**Simple, focused tables:**

- **`players`** - Player information
- **`rankings`** - All ranking data with proper indexing
- **`scraping_logs`** - Simple job tracking

**Key fields for analytics:**
- `rank_ecr` - Expert consensus ranking
- `rank_std` - Standard deviation (for tier generation)
- `rank_min/max` - Expert range
- `tier` - Generated tier (for Boris Chen style analysis)

## âš™ï¸ **Configuration**

Set via environment variables:

```bash
# Database
DATABASE_URL=postgresql://user:pass@host:5432/db

# Application  
DEBUG=true
PORT=8000
CURRENT_YEAR=2025

# Scraping
SCRAPING_DELAY=1.0
MAX_RETRIES=3
```

## ğŸ”„ **Automated Scheduling**

- **Draft Season** (July-August): Every 6 hours
- **Regular Season** (September+): 3x daily (8am, 2pm, 8pm)
- **Health checks**: Every 30 minutes

## ğŸ“Š **Next Steps: Analytics**

This pipeline provides **clean data** for building:

1. **Tier Generation** (Boris Chen style using `rank_std`)
2. **Player Movement Tracking** (week-over-week changes)
3. **Interactive Dashboards** (React frontend)
4. **Trade Analysis** (player value trends)

## ğŸ³ **Production Deployment**

### **Docker Compose (Simple)**
- Use provided `docker-compose.yml`
- Update environment variables
- Use external PostgreSQL for production

### **Cloud Deployment**
- Deploy containers to any cloud platform
- Use managed PostgreSQL (AWS RDS, Google Cloud SQL, etc.)
- Set proper environment variables

## ğŸ› ï¸ **Development**

**Project Structure:**
```
app/
â”œâ”€â”€ config.py              # Simple configuration
â”œâ”€â”€ database/
â”‚   â””â”€â”€ models.py          # Clean SQLAlchemy models
â”œâ”€â”€ scraper/
â”‚   â””â”€â”€ fantasypros.py     # FantasyPros scraper
â”œâ”€â”€ api/
â”‚   â””â”€â”€ server.py          # FastAPI server
â””â”€â”€ scheduler.py           # Simple scheduling

main.py                    # CLI entry point
requirements.txt           # Minimal dependencies
Dockerfile                 # Container setup
docker-compose.yml         # Local development
```

**Philosophy:**
- âœ… **Simple & Clean** - No overengineering
- âœ… **Modular** - Easy to understand and modify  
- âœ… **DRY** - Reusable components
- âœ… **Focused** - Built for analytics, not enterprise scale

---

**Perfect for hobby-grade fantasy football analytics! ğŸˆ** 